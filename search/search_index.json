{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"DbDeclare","text":"<p>A declarative layer for your database, built on SQLAlchemy.</p> <p>The code is on GitHub.</p> <p>The docs are hosted on GitHub pages.</p>"},{"location":"#overview","title":"Overview","text":""},{"location":"#what-is-it","title":"What is it?","text":"<p>DbDeclare is a Python package that helps you create and manage entities in your database cluster, like databases, roles, access control, and (eventually) more. It aims to fill the gap between SQLAlchemy (SQLA) and infrastructure as code (IaC).</p>"},{"location":"#why-use-it","title":"Why use it?","text":"<p>DbDeclare does what SQLA does but for database entities beyond tables and columns. You can:</p> <ul> <li>Declare desired state in Python</li> <li>Avoid maintaining raw SQL</li> <li>Tightly integrate your databases, roles, access control, and more with your tables</li> </ul> <p>Future versions will have more features, and you will be able to:</p> <ul> <li>Have version control over database changes (like Alembic)</li> <li>Define upgrades/downgrades without explicitly defining the changes (like autogen)</li> </ul> <p>Additionally, DbDeclare is:</p> <ul> <li>Typed: Type-checking done via mypy</li> <li>Thoroughly commented: There are docstrings for every method and class</li> <li>Well-tested: Though this is a new package under active development, solid test coverage is a high priority</li> </ul> <p>Running SQL scripts before SQLA and after IaC can be messy and hard to maintain. If you prefer to have databases, roles, and the like declared alongside your infrastructure, then there are great tools available for that, like Terraform and Pulumi's providers for Postgres and MySQL. So if you want it tied to that, great! But if, like me, you want it closer to your application code and alongside SQLA, this tool likely makes more sense for you.</p>"},{"location":"#requirements","title":"Requirements","text":"<p>This requires a recent version of Python. Works with Python 3.11 or higher. We recommend pyenv to install any versions of Python you need and don't currently have installed.</p> <p>This also requires a compatible driver/package for your database of choice, like psycopg for Postgres. You'll also need a functioning cluster to interact with (the example below shows a way to do so via Docker).</p> <p>SQLAlchemy is a dependency and will be installed when you install DbDeclare. DbDeclare works with SQLAlchemy 2.0.0 or higher.</p>"},{"location":"#installation","title":"Installation","text":"<p>DbDeclare is published on PyPi. You can install it with <code>pip</code> or any tool that uses <code>pip</code> under the hood. This is typically installed in a virtual environment.</p> <pre><code>&gt; pip install db-declare\n</code></pre>"},{"location":"#example","title":"Example","text":"<p>Here is a simple Postgres example. We will create a database and a user, and make sure the user can connect to the database. You need a Postgres cluster/instance and a python environment.</p> <p>If needed, an easy way to spin up a Postgres instance is with Docker, specifically the official Postgres image:</p> <pre><code>&gt; docker run --rm --name postgres -e POSTGRES_PASSWORD=postgres -p 127.0.0.1:5432:5432/tcp postgres\n</code></pre> <p>This spins up a Postgres instance with the default database name of <code>postgres</code>, an admin user of <code>postgres</code> with the password <code>postgres</code>, on port <code>5432</code>.</p> <p>Assuming you have a Python environment set up, DbDeclare installed, and psycopg installed (<code>pip install psycopg</code>), you can create a database and a user that can connect to it like this:</p> <pre><code>from sqlalchemy import create_engine\nfrom dbdeclare.controller import Controller\nfrom dbdeclare.data_structures import GrantOn, Privilege\nfrom dbdeclare.entities import Database, Role\ndef main() -&gt; None:\n# declare the database\nfalafel_db = Database(name=\"falafel\")\n# declare the user\nRole(\nname=\"hungry_user\",\nlogin=True,  # (1)!\npassword=\"fakepassword\",  # (2)!\ngrants=[GrantOn(privileges=[Privilege.CONNECT], on=[falafel_db])],  # (3)!\n)\n# create engine with admin user and default database\nengine = create_engine(url=\"postgresql+psycopg://postgres:postgres@127.0.0.1:5432/postgres\")  # (4)!\n# create all entities and grant all privileges\nController.run_all(engine=engine)\nif __name__ == \"__main__\":\nmain()\n</code></pre> <ol> <li>Make sure this role can log in (make it a user)</li> <li>Provide a password for the user to log in with</li> <li>Specify that this user can connect to the <code>falafel</code> database</li> <li>The engine to run DbDeclare must have admin privileges, so we use the <code>postgres</code> user here</li> </ol> <p>After running this script, you should be able to access the <code>falafel</code> database as <code>hungry_user</code>. You can try it out with <code>psql</code> (if you don't have it installed, find it here). In a separate shell from where the docker run command is running, you can run:</p> <pre><code>&gt; psql -h 127.0.0.1 -p 5432 -U hungry_user -d falafel\n\npassword for user hungry_user: ***\n\nfalafel=&gt;\n</code></pre> <p>Voila! Check out the user guide for more involved use cases.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>Check out development, testing, and contributing guidance here.</p>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the terms of the MIT license.</p>"},{"location":"contributing/","title":"Contributing","text":"<p>We'd love to see folks contribute! Below you will find instructions to:</p> <ul> <li>Set up the environment and pre-commit</li> <li>Run type checking and tests</li> <li>Develop DbDeclare</li> <li>Develop documentation</li> <li>Contribute via the Git workflow</li> </ul>"},{"location":"contributing/#prerequisites","title":"Prerequisites","text":""},{"location":"contributing/#python","title":"Python","text":"<p>Make sure you have the right version on your machine. You can install pyenv then use it to install the desired version if needed:</p> <pre><code>&gt; pyenv install 3.11.0\n</code></pre> <p>Please refer to the pyenv usage instructions for more information on that tool.</p>"},{"location":"contributing/#database","title":"Database","text":"<p>You need a functioning database instance/cluster and drivers for the database you choose. DbDeclare currently only supports Postgres.</p>"},{"location":"contributing/#postgres","title":"Postgres","text":"<p>An easy way to set up Postgres on your machine is to do so via Docker. Once you have it set up on your machine, you can pull the official Postgres image, run it locally, and port-forward it:</p> <pre><code>&gt; docker run --rm --name postgres -e POSTGRES_PASSWORD=postgres -p 127.0.0.1:5432:5432/tcp postgres\n</code></pre> <p>This will spin up a Postgres instance with the following properties:</p> <ul> <li>host: <code>127.0.0.1</code></li> <li>port: <code>5432</code></li> <li>admin username: <code>postgres</code></li> <li>admin password: <code>postgres</code></li> <li>default database name: <code>postgres</code></li> </ul> <p>Note that if there is already something running on port <code>5432</code>, this will fail. You need to stop whatever process is running there, or change the port-forward statement to a different port (<code>5433:5432</code> would forward to port <code>5433</code>, for example).</p> <p>To \"restart\" the instance, you can simply <code>ctrl-C</code> and run the command again.</p>"},{"location":"contributing/#setup","title":"Setup","text":"<p>With prerequisites in place, we can start setting up the project for development.</p>"},{"location":"contributing/#environment","title":"Environment","text":"<p>We use Poetry to build, package, and publish the project. You can find installation instructions for Poetry here.</p> <p>Once Poetry is installed, you can install the project and dependencies from the root directory:</p> <pre><code>&gt; poetry install\n</code></pre> <p>You might run into an issue with psycopg installation. For development, we use the pure Python installation, which has some requirements. If you have trouble getting it to work, you can always use the binary installation instead.</p>"},{"location":"contributing/#pre-commit","title":"Pre-commit","text":"<p>We use pre-commit for consistent code formatting. Our configuration includes other tools like black, isort, and flake8. Check out this blog post to learn more.</p> <p>The configuration for pre-commit lives in the <code>.pre-commit-config.yaml</code> file, and the configuration for the other tools exists in a combination of <code>tox.ini</code> and <code>pyproject.toml</code>.</p> <p>Pre-commit is installed as a development dependency. To install the configuration in your local environment, run:</p> <pre><code>&gt; pre-commit install\n</code></pre> <p>This will now run all the configured tools every time you attempt to commit your code. If there is a repeated failure, you will need to adjust your changes; the error messages are specific and helpful, they should guide you to the issue.</p> <p>To run the tools manually, you can:</p> <pre><code>&gt; pre-commit run --all-files\n</code></pre>"},{"location":"contributing/#develop-dbdeclare","title":"Develop DbDeclare","text":""},{"location":"contributing/#type-checks","title":"Type checks","text":"<p>We use mypy for type checking. We configure it in the <code>pyproject.toml</code> file. You can run it on the default setting (which checks all files) by simply running <code>mypy</code> from the root of the project. Running mypy is also the first step of the continuous integration (CI) process, so when you make a pull request, it will be automatically type-checked. The type checking must succeed for the pull request to be accepted.</p>"},{"location":"contributing/#tests","title":"Tests","text":"<p>We use pytest for running tests. Some tests (most integration tests and some documentation tests) require a running Postgres instance with the following characteristics:</p> <ul> <li>host: <code>127.0.0.1</code></li> <li>port: <code>5432</code></li> <li>username: <code>postgres</code></li> <li>password: <code>postgres</code></li> <li>database name: <code>postgres</code></li> </ul> <p>As mentioned earlier, an easy way to do this is via Docker:</p> <pre><code>&gt; docker run --rm --name postgres -e POSTGRES_PASSWORD=postgres -p 127.0.0.1:5432:5432/tcp postgres\n</code></pre> <p>Once that is running, in a seperate shell window, you can run:</p> <pre><code>&gt; pytest tests\n</code></pre> <p>You can use all the standard <code>pytest</code> syntax to specify tests. Some common specifications might be to only run unit tests, integration tests, or documentation tests. These are split up by path, so you can run <code>pytest tests/unit</code> to run all unit tests.</p> <p>Running tests is also part of the CI process. When you make a pull request, all tests will run, and they must pass in order to be accepted.</p>"},{"location":"contributing/#develop-documentation","title":"Develop documentation","text":"<p>We use mkdocs specifically with the material theme to build our documentation. The configuration for it lives in <code>mkdocs.yml</code>, and the dependencies are specified in the docs group in the <code>pyproject.toml</code> file. The markdown all resides in the <code>docs</code> directory, and the larger code examples used throughout are in <code>docs_src</code>. Refer to the mkdocs documentation for more detail if needed, but to serve it locally at <code>localhost:8000</code>, you can simply run:</p> <pre><code>&gt; mkdocs serve\n</code></pre>"},{"location":"contributing/#git-flow","title":"Git flow","text":"<p>We follow a fairly standard git workflow that has been documented plenty of times elsewhere. Here is a great explanation of it.</p> <p>Once a change is reviewed, approved, and merged, the maintainers will create a release and publish a new version of the package.</p>"},{"location":"guide/","title":"User guide","text":"<p>This guide will use one main over-arching example as a way to walk through everything DbDeclare can do. Some details are omitted as they are unnecessary for the example, and some are contrived to show more functionality.</p>"},{"location":"guide/#the-example","title":"The example","text":"<p>Let's say we have an application that takes in articles from a variety of news sites, clusters them, and exposes the clusters via an API. We also want to store API logs (yes, this is typically not done in tables in Postgres, please bear with me for the sake of the example). We want to accommodate 3 stages in our cluster: <code>test</code>, <code>dev</code>, and <code>prod</code> (yes, it is typically best practice to have prod in a completely separate cluster/instance, but humor me for this example). So for each stage, we want the following:</p> <ul> <li>Schemas and tables:<ul> <li>In the <code>default</code> schema, tables for: <code>Article</code>, <code>Keyword</code>, <code>Cluster</code></li> <li>In a <code>log</code> schema, tables for: <code>BadRequest</code>, <code>GoodRequest</code></li> </ul> </li> <li>Groups (roles that will not log in but define privileges):<ul> <li>An <code>etl_writer</code> role that can insert and update on <code>Article</code> and <code>Keyword</code></li> <li>A <code>ml_writer</code> role that can insert and update on <code>Cluster</code></li> <li>A <code>reader</code> role that can select on <code>Article</code>, <code>Keyword</code>, and <code>Cluster</code></li> <li>A <code>log</code> role that can insert, update, and select on <code>BadRequest</code> and <code>GoodRequest</code> (omit for <code>test</code>)</li> </ul> </li> <li>Users (roles that will log in):<ul> <li>An <code>etl</code> role that is a member of <code>etl_writer</code> and <code>reader</code></li> <li>An <code>ml</code> role that is a member of <code>ml_writer</code> and <code>reader</code></li> <li>An <code>api</code> role that is a member of <code>log</code> and <code>reader</code> (omit for <code>test</code>)</li> </ul> </li> </ul> <p>Sound like a lot? No worries, we'll take it step by step. Let's start with our databases. If this seems straightforward, and you'd prefer to just see the entire example, skip ahead.</p>"},{"location":"guide/controller/","title":"Controller","text":"<p>First, we'll go over the basics and examine the <code>Controller</code> class. Then, we'll finish up our example.</p>"},{"location":"guide/controller/#the-controller-class","title":"The Controller class","text":"<p>You can import the <code>Controller</code> like so:</p> <pre><code>from dbdeclare.controller import Controller\n</code></pre> <p>The <code>Controller</code> executes commands in the cluster. It looks at everything you've declared and (depending on the function you call) creates/drops entities and grants/revokes privileges. Under the hood, it iterates over all entities and executes their specific commands. So if all you have declared is something like:</p> <pre><code>db = Database(name=\"dev\")\n</code></pre> <p>The only SQL executed from <code>Controller.run_all</code> will be:</p> <pre><code>CREATE DATABASE dev;\n</code></pre> <p>There are a handful of functions to choose from. <code>run_all</code> and <code>remove_all</code> are the most likely entrypoints. <code>run_all</code> runs <code>create_all</code> which creates all declared entities, then runs <code>grant_all</code> which grants all declared privileges. <code>remove_all</code> runs <code>revoke_all</code> which revokes all privileges, then runs <code>drop_all</code> which drops all declared entities.  Take a look at the class docstrings for more detail. The <code>Controller</code> interacts heavily with the underlying <code>Entity</code> class and is to some extent a wrapper around it.</p> <p>For what it's worth, this is where a lot of future development will go: we'd like to eventually have updates, change detection, integration with Alembic, and more.</p>"},{"location":"guide/controller/#example","title":"Example","text":"<p>Let's finish up our example. We have all our entities declared, and we have all our grants declared as well. Now we just need to execute:</p> <pre><code>from sqlalchemy import create_engine\nfrom sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column\nfrom dbdeclare.controller import Controller\n# omitted code between\n# create engine with admin user and default database\nengine = create_engine(url=\"postgresql+psycopg://postgres:postgres@127.0.0.1:5432/postgres\")\n# create all entities and grant all privileges\nController.run_all(engine=engine)\n</code></pre> <p>We import <code>create_engine</code> from SQLA and <code>Controller</code> from DbDeclare. We create an engine, and make sure to provide a user with admin privileges (you might need to adjust your cluster url relative to the example). Pass the engine to the <code>run_all</code> method, and we're done! It'll create all the entities and grant all privileges.</p> <p>The entire, complete file:</p> <pre><code>from sqlalchemy import create_engine\nfrom sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column\nfrom dbdeclare.controller import Controller\nfrom dbdeclare.data_structures import GrantOn, Privilege\nfrom dbdeclare.entities import Database, DatabaseContent, Role, Schema\nclass ExampleBase(DeclarativeBase):\npass\nclass Article(ExampleBase):\n__tablename__ = \"article\"\nid: Mapped[int] = mapped_column(primary_key=True)\nclass Keyword(ExampleBase):\n__tablename__ = \"keyword\"\nid: Mapped[int] = mapped_column(primary_key=True)\nclass Cluster(ExampleBase):\n__tablename__ = \"cluster\"\nid: Mapped[int] = mapped_column(primary_key=True)\nclass BadRequest(ExampleBase):\n__tablename__ = \"bad_request\"\n__table_args__ = {\"schema\": \"log\"}\nid: Mapped[int] = mapped_column(primary_key=True)\nclass GoodRequest(ExampleBase):\n__tablename__ = \"good_request\"\n__table_args__ = {\"schema\": \"log\"}\nid: Mapped[int] = mapped_column(primary_key=True)\ndef declare_stage(stage: str) -&gt; None:\ndb = Database(name=stage)\n# \"groups\" aka non-login roles\netl_writer = Role(name=f\"{stage}_etl_writer\")\nml_writer = Role(name=f\"{stage}_ml_writer\")\nreader = Role(name=f\"{stage}_reader\")\n# \"users\" aka login roles\nRole(name=f\"{stage}_etl\", login=True, password=\"fake\", in_role=[etl_writer, reader])\nRole(name=f\"{stage}_ml\", login=True, password=\"fake\", in_role=[ml_writer, reader])\n# create extra schemas\nlog_schema = Schema(name=\"log\", database=db)\n# create db content\ncontent = DatabaseContent(name=\"main\", database=db, sqlalchemy_base=ExampleBase, schemas=[log_schema])\n# grant privileges\netl_writer.grant(\ngrants=[\nGrantOn(\nprivileges=[Privilege.INSERT, Privilege.UPDATE],\non=[content.tables[Article.__tablename__], content.tables[Keyword.__tablename__]],\n)\n]\n)\nml_writer.grant(\ngrants=[GrantOn(privileges=[Privilege.INSERT, Privilege.UPDATE], on=[content.tables[Cluster.__tablename__]])]\n)\nreader.grant(\ngrants=[\nGrantOn(\nprivileges=[Privilege.SELECT],\non=[\ncontent.tables[Article.__tablename__],\ncontent.tables[Keyword.__tablename__],\ncontent.tables[Cluster.__tablename__],\n],\n)\n]\n)\n# create log role and grant privileges if not test stage\nif stage != \"test\":\nlog_role = Role(\nname=f\"{stage}_logger\",\ngrants=[\nGrantOn(privileges=[Privilege.USAGE], on=[log_schema]),\nGrantOn(\nprivileges=[Privilege.INSERT, Privilege.SELECT, Privilege.UPDATE],\non=[content.tables[BadRequest.__tablename__], content.tables[GoodRequest.__tablename__]],\n),\n],\n)\nRole(name=f\"{stage}_api\", login=True, password=\"fake\", in_role=[log_role, reader])\ndef main() -&gt; None:\n# declare stages\nstages = [\"test\", \"dev\", \"prod\"]\nfor stage in stages:\ndeclare_stage(stage)\n# create engine with admin user and default database\nengine = create_engine(url=\"postgresql+psycopg://postgres:postgres@127.0.0.1:5432/postgres\")\n# create all entities and grant all privileges\nController.run_all(engine=engine)\nif __name__ == \"__main__\":\nmain()\n</code></pre> <p>If you run this (with an active Postgres instance/cluster), it should create all the databases, roles, schemas, and tables. It should also grant all the privileges declared. You can test via psql:</p> <pre><code>&gt; psql -h 127.0.0.1 -U dev_api -d dev\n\npassword for user dev_api: ***\n\ndev=&gt; SELECT * FROM log.good_request;\n id \n----\n(0 rows)\n</code></pre> <p>There's nothing in there, but the database, schema, role, and access privileges are all present! Woo!</p> <p>That's all for now. The future holds more features, and this documentation will be updated as they're added.</p>"},{"location":"guide/databases/","title":"Databases","text":"<p>First, we'll go over basics and examine the <code>Database</code> class. Then, we'll start to build our example. You can also skip ahead to the example.</p>"},{"location":"guide/databases/#the-database-class","title":"The Database class","text":"<p>You can import <code>Database</code> like so:</p> <pre><code>from dbdeclare.entities import Database\n</code></pre> <p><code>Database</code> is a representation of a Postgres database. It is a cluster-wide entity. This means each database in your cluster must have a unique name. The <code>__init__</code> args correspond to the SQL <code>CREATE DATABASE</code> arguments found in the Postgres documentation.</p> <p>Take a look at the class docstrings for more detail, like an explanation of the <code>__init__</code> args, the various methods defined, what classes it inherits from, and more.</p>"},{"location":"guide/databases/#example","title":"Example","text":"<p>Let's start building our example. We need a database for each stage, so let's create a function that takes a stage (like <code>dev</code> or <code>prod</code>) as input and declares a database with it:</p> <pre><code>from dbdeclare.entities import Database\ndef declare_stage(stage: str) -&gt; None:\nDatabase(name=stage)\n</code></pre> <p>This imports the <code>Database</code> class, defines a function <code>declare_stage</code> that accepts a string name of a stage, and declares a <code>Database</code> with the stage as the name. Now let's define a main function that creates all three stages we want to create:</p> <pre><code>from dbdeclare.entities import Database\ndef declare_stage(stage: str) -&gt; None:\nDatabase(name=stage)\ndef main() -&gt; None:\nstages = [\"test\", \"dev\", \"prod\"]\nfor stage in stages:\ndeclare_stage(stage)\n</code></pre> <p>Here, we add a <code>main</code> function with no inputs, define a list of desired stages, loop over them, and run the <code>declare_stage</code> function for each stage.</p> <p>You can run the entire file:</p> <pre><code>from dbdeclare.entities import Database\ndef declare_stage(stage: str) -&gt; None:\nDatabase(name=stage)\ndef main() -&gt; None:\nstages = [\"test\", \"dev\", \"prod\"]\nfor stage in stages:\ndeclare_stage(stage)\nif __name__ == \"__main__\":\nmain()\n</code></pre> <p>This declares all three databases. Excellent! Note that we haven't created anything in our cluster yet, we have only declared our databases in code. We'll get to creation, but first let's add some roles.</p>"},{"location":"guide/grants/","title":"Grants","text":"<p>First, we'll go over the details of how grants are implemented. Then, we'll continue to build our example. You can also skip ahead to the example.</p>"},{"location":"guide/grants/#grantable-entities","title":"Grantable entities","text":"<p>The <code>Grantable</code> class is an internal class used by DbDeclare (aka you won't use it unless you are developing and extending the package). It defines behavior for any entity that can have privileges granted to it. This includes entities like databases, schemas, and tables. Grantable entities work in tandem with <code>Role</code>s to declare access privileges, like connecting to a database or selecting from a table. Ultimately, you are able to declare relationships that result in a <code>GRANT {privileges} ON {entity_type} {entity} TO {role}</code>.</p>"},{"location":"guide/grants/#privileges","title":"Privileges","text":"<p>Privileges are a set list of access control definitions, check out the Postgres documentation for a complete overview. DbDeclare defines them all in a Python <code>enum</code>:</p> <pre><code>from dbdeclare.data_structures import Privilege\n</code></pre> <p>Use this to declare what privileges you want to when you declare a grant.</p>"},{"location":"guide/grants/#multiple-ways-to-grant","title":"Multiple ways to grant","text":"<p>Grantable entities and <code>Role</code>s can both declare grants.</p>"},{"location":"guide/grants/#from-a-role","title":"From a role","text":"<p>The <code>Role</code> class has a <code>grant</code> method that accepts a <code>Sequence[GrantOn]</code>, where <code>GrantOn</code> can be found in <code>data_structures</code>:</p> <pre><code>from dbdeclare.data_structures import GrantOn\n</code></pre> <p><code>GrantOn</code> is a dataclass that has two attributes: <code>privileges</code>, which is a <code>Sequence[Privilege]</code>, and <code>on</code>, which is a sequence of <code>Grantable</code> entities to grant those privileges on.</p> <p>You can also pass in a <code>Sequence[GrantOn]</code> when you declare a <code>Role</code> via the <code>__init__</code> method, if it is more convenient to do so.</p>"},{"location":"guide/grants/#from-a-grantable-entity","title":"From a grantable entity","text":"<p>Anything that inherits from <code>Grantable</code> also has a <code>grant</code> method, but this one accepts a <code>Sequence[GrantTo]</code>. <code>GrantTo</code> can also be found in <code>data_structures</code>:</p> <pre><code>from dbdeclare.data_structures import GrantTo\n</code></pre> <p><code>GrantTo</code> is a dataclass that has two attributes: <code>privileges</code>, which is a <code>Sequence[Privilege]</code>, and <code>to</code>, which is a sequence of <code>Role</code>s to grant those privileges to.</p> <p>You can also pass in a <code>Sequence[GrantTo]</code> when you declare any grantable entity via the <code>__init__</code> method, if it is more convenient to do so.</p>"},{"location":"guide/grants/#how-grants-are-stored","title":"How grants are stored","text":"<p>So what actually happens when you run the <code>grant</code> methods described above? We store them in the <code>Role</code> that  access is granted to for easy synchronization. DbDeclare also makes sure that the order of creates and grants is correct so that execution doesn't fail. Each <code>Role</code> has an attribute named <code>grants</code> of type <code>GrantStore</code>, which is an alias for <code>dict[Grantable, set[Privilege]]</code>. This structure is easy to translate to and from Postgres, and makes sure there is a single source of truth within the code.</p> <p>As always, I encourage you to peek at the source code and read the docstrings for details!</p>"},{"location":"guide/grants/#example","title":"Example","text":"<p>Let's add grants to our example. We have declared all the entities we want to create, so now we can run some <code>grant</code> statements.</p> <pre><code>from dbdeclare.data_structures import GrantOn, Privilege\n</code></pre> <p>For our example, I've opted to grant privileges from the point of view of <code>Role</code>s only, which means I import <code>GrantOn</code> but not <code>GrantTo</code>.</p> <pre><code># omitted code above\n# grant privileges\netl_writer.grant(\ngrants=[\nGrantOn(\nprivileges=[Privilege.INSERT, Privilege.UPDATE],\non=[content.tables[Article.__tablename__], content.tables[Keyword.__tablename__]],\n)\n]\n)\nml_writer.grant(\ngrants=[GrantOn(privileges=[Privilege.INSERT, Privilege.UPDATE], on=[content.tables[Cluster.__tablename__]])]\n)\nreader.grant(\ngrants=[\nGrantOn(\nprivileges=[Privilege.SELECT],\non=[\ncontent.tables[Article.__tablename__],\ncontent.tables[Keyword.__tablename__],\ncontent.tables[Cluster.__tablename__],\n],\n)\n]\n)\n# omitted code below\n</code></pre> <p>Here, we grab our references for <code>etl_writer</code>, <code>ml_writer</code>, and <code>reader</code>, and declare grants for each of them. We allow <code>etl_writer</code> to insert and update on the <code>article</code> and <code>keyword</code> table, we allow <code>ml_writer</code> to insert and update on the <code>cluster</code> table, and we allow <code>reader</code> to select from all three of those tables. Note that we don't have to grant usage of the default schema as (typically) usage is granted to all users by default. Depending on your set up, you may need to grant connect on the roles to each database.</p> <pre><code># omitted code above\nif stage != \"test\":\nlog_role = Role(\nname=f\"{stage}_logger\",\ngrants=[\nGrantOn(privileges=[Privilege.USAGE], on=[log_schema]),\nGrantOn(\nprivileges=[Privilege.INSERT, Privilege.SELECT, Privilege.UPDATE],\non=[content.tables[BadRequest.__tablename__], content.tables[GoodRequest.__tablename__]],\n),\n],\n)\nRole(name=f\"{stage}_api\", login=True, password=\"fake\", in_role=[log_role, reader])\n# omitted code below\n</code></pre> <p>We also need to grant insert, select, and update privileges to <code>log_role</code> on both tables in the <code>log</code> schema. Since this is a non-default schema, we first grant usage on the schema, then we grant the desired privileges on both tables. Note that this is done in the creation of the role, in contrast to the previous examples that call <code>grant</code> on the roles after they were declared. Do whatever makes more sense for you.</p> <p>Here is the entire file now:</p> <pre><code>from sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column\nfrom dbdeclare.data_structures import GrantOn, Privilege\nfrom dbdeclare.entities import Database, DatabaseContent, Role, Schema\nclass ExampleBase(DeclarativeBase):\npass\nclass Article(ExampleBase):\n__tablename__ = \"article\"\nid: Mapped[int] = mapped_column(primary_key=True)\nclass Keyword(ExampleBase):\n__tablename__ = \"keyword\"\nid: Mapped[int] = mapped_column(primary_key=True)\nclass Cluster(ExampleBase):\n__tablename__ = \"cluster\"\nid: Mapped[int] = mapped_column(primary_key=True)\nclass BadRequest(ExampleBase):\n__tablename__ = \"bad_request\"\n__table_args__ = {\"schema\": \"log\"}\nid: Mapped[int] = mapped_column(primary_key=True)\nclass GoodRequest(ExampleBase):\n__tablename__ = \"good_request\"\n__table_args__ = {\"schema\": \"log\"}\nid: Mapped[int] = mapped_column(primary_key=True)\ndef declare_stage(stage: str) -&gt; None:\ndb = Database(name=stage)\n# \"groups\" aka non-login roles\netl_writer = Role(name=f\"{stage}_etl_writer\")\nml_writer = Role(name=f\"{stage}_ml_writer\")\nreader = Role(name=f\"{stage}_reader\")\n# \"users\" aka login roles\nRole(name=f\"{stage}_etl\", login=True, password=\"fake\", in_role=[etl_writer, reader])\nRole(name=f\"{stage}_ml\", login=True, password=\"fake\", in_role=[ml_writer, reader])\n# create extra schemas\nlog_schema = Schema(name=\"log\", database=db)\n# create db content\ncontent = DatabaseContent(name=\"main\", database=db, sqlalchemy_base=ExampleBase, schemas=[log_schema])\n# grant privileges\netl_writer.grant(\ngrants=[\nGrantOn(\nprivileges=[Privilege.INSERT, Privilege.UPDATE],\non=[content.tables[Article.__tablename__], content.tables[Keyword.__tablename__]],\n)\n]\n)\nml_writer.grant(\ngrants=[GrantOn(privileges=[Privilege.INSERT, Privilege.UPDATE], on=[content.tables[Cluster.__tablename__]])]\n)\nreader.grant(\ngrants=[\nGrantOn(\nprivileges=[Privilege.SELECT],\non=[\ncontent.tables[Article.__tablename__],\ncontent.tables[Keyword.__tablename__],\ncontent.tables[Cluster.__tablename__],\n],\n)\n]\n)\n# create log role and grant privileges if not test stage\nif stage != \"test\":\nlog_role = Role(\nname=f\"{stage}_logger\",\ngrants=[\nGrantOn(privileges=[Privilege.USAGE], on=[log_schema]),\nGrantOn(\nprivileges=[Privilege.INSERT, Privilege.SELECT, Privilege.UPDATE],\non=[content.tables[BadRequest.__tablename__], content.tables[GoodRequest.__tablename__]],\n),\n],\n)\nRole(name=f\"{stage}_api\", login=True, password=\"fake\", in_role=[log_role, reader])\ndef main() -&gt; None:\nstages = [\"test\", \"dev\", \"prod\"]\nfor stage in stages:\ndeclare_stage(stage)\nif __name__ == \"__main__\":\nmain()\n</code></pre> <p>We have declared everything we set out to declare. Nice! All that's left is to actually create all of this in the database. Let's run it!</p>"},{"location":"guide/roles/","title":"Roles","text":"<p>First, we'll go over basics and examine the <code>Role</code> class. Then, we'll continue to build our example. You can also skip ahead to the example.</p>"},{"location":"guide/roles/#the-role-class","title":"The Role class","text":"<p>You can import <code>Role</code> like so:</p> <pre><code>from dbdeclare.entities import Role\n</code></pre> <p><code>Role</code> is a representation of a Postgres role. It is a cluster-wide entity. This means each role in your cluster must have a unique name. The <code>__init__</code> args correspond to the SQL <code>CREATE ROLE</code> arguments found in the Postgres documentation.</p> <p>Take a look at the class docstrings for more detail, like an explanation of the <code>__init__</code> args, the various methods defined, what classes it inherits from, and more. <code>Role</code> is unique amongst the entities because you can only grant privileges to a role. We'll go into more detail when we discuss grants, but roles store the declared grants and call all the granted target entity <code>grant</code> methods to actually execute grants. Point being, <code>Role</code> is unique and it is worth taking a look at the source code.</p>"},{"location":"guide/roles/#example","title":"Example","text":"<p>Let's keep building our example. We have our databases, now we need our roles. We have a lot: some that act like groups (roles that don't log in and typically have access privileges granted to them) and some that are users (roles that can log in). We don't need to change our <code>main</code> function, just the <code>declare_stage</code> one:</p> <pre><code>from dbdeclare.entities import Database, Role\ndef declare_stage(stage: str) -&gt; None:\nDatabase(name=stage)  # (1)!\n# \"groups\" aka non-login roles\netl_writer = Role(name=f\"{stage}_etl_writer\")\nml_writer = Role(name=f\"{stage}_ml_writer\")\nreader = Role(name=f\"{stage}_reader\")\n# \"users\" aka login roles\nRole(name=f\"{stage}_etl\", login=True, password=\"fake\", in_role=[etl_writer, reader])\nRole(name=f\"{stage}_ml\", login=True, password=\"fake\", in_role=[ml_writer, reader])\n# create log role and grant privileges if not test stage\nif stage != \"test\":\nlog_role = Role(name=f\"{stage}_logger\")\nRole(name=f\"{stage}_api\", login=True, password=\"fake\", in_role=[log_role, reader])\n</code></pre> <ol> <li>We're keeping the function header and <code>Database</code> definition from before.</li> </ol> <p>Okay, we added a bunch of lines. Let's zoom in and break down what they're doing.</p> <p><pre><code># omitted code above\n# \"groups\" aka non-login roles\netl_writer = Role(name=f\"{stage}_etl_writer\")\nml_writer = Role(name=f\"{stage}_ml_writer\")\nreader = Role(name=f\"{stage}_reader\")\n# \"users\" aka login roles\nRole(name=f\"{stage}_etl\", login=True, password=\"fake\", in_role=[etl_writer, reader])\nRole(name=f\"{stage}_ml\", login=True, password=\"fake\", in_role=[ml_writer, reader])\n# create log role and grant privileges if not test stage\nif stage != \"test\":\nlog_role = Role(name=f\"{stage}_logger\")\nRole(name=f\"{stage}_api\", login=True, password=\"fake\", in_role=[log_role, reader])\n# omitted code below\n</code></pre> The highlighted lines create the etl_writer, ml_writer, and reader groups we want. We have not implemented the access privileges yet; that'll come later. We make sure to prepend the names with the <code>stage</code> input so that they are unique across the cluster, but clearly defined for each stage we want. For example, we'll have a <code>test_reader</code>, <code>dev_reader</code>, and <code>prod_reader</code> as a result of running this for all three stages. The default argument for <code>login</code> is <code>False</code>, so these roles cannot log in and have no password associated with them.</p> <pre><code># omitted code above\n# \"groups\" aka non-login roles\netl_writer = Role(name=f\"{stage}_etl_writer\")\nml_writer = Role(name=f\"{stage}_ml_writer\")\nreader = Role(name=f\"{stage}_reader\")\n# \"users\" aka login roles\nRole(name=f\"{stage}_etl\", login=True, password=\"fake\", in_role=[etl_writer, reader])\nRole(name=f\"{stage}_ml\", login=True, password=\"fake\", in_role=[ml_writer, reader])\n# create log role and grant privileges if not test stage\nif stage != \"test\":\nlog_role = Role(name=f\"{stage}_logger\")\nRole(name=f\"{stage}_api\", login=True, password=\"fake\", in_role=[log_role, reader])\n# omitted code below\n</code></pre> <p>The highlighted lines create the etl and ml users we want. We make sure to specify <code>login=True</code> and provide a (dummy) password. We also specify what groups they are in. For example, the <code>dev_etl</code> user is declared to be in the <code>dev_etl_writer</code> and <code>dev_reader</code> roles, where it will attain all the privileges granted to them (once we grant privileges later). We don't assign the output to a variable because we aren't referring to these roles later.</p> <pre><code># omitted code above\n# \"groups\" aka non-login roles\netl_writer = Role(name=f\"{stage}_etl_writer\")\nml_writer = Role(name=f\"{stage}_ml_writer\")\nreader = Role(name=f\"{stage}_reader\")\n# \"users\" aka login roles\nRole(name=f\"{stage}_etl\", login=True, password=\"fake\", in_role=[etl_writer, reader])\nRole(name=f\"{stage}_ml\", login=True, password=\"fake\", in_role=[ml_writer, reader])\n# create log role and grant privileges if not test stage\nif stage != \"test\":\nlog_role = Role(name=f\"{stage}_logger\")\nRole(name=f\"{stage}_api\", login=True, password=\"fake\", in_role=[log_role, reader])\n# omitted code below\n</code></pre> <p>The last lines highlighted here create a group and a user for any stage that isn't the test stage. Otherwise, you've now seen this all before! So there will be a <code>dev_logger</code> and a <code>prod_logger</code>, but no <code>test_logger</code>.</p> <p>You can then run the entire file (which won't make anything happen) just to see that it doesn't error out:</p> <pre><code>from dbdeclare.entities import Database, Role\ndef declare_stage(stage: str) -&gt; None:\nDatabase(name=stage)  # (1)!\n# \"groups\" aka non-login roles\netl_writer = Role(name=f\"{stage}_etl_writer\")\nml_writer = Role(name=f\"{stage}_ml_writer\")\nreader = Role(name=f\"{stage}_reader\")\n# \"users\" aka login roles\nRole(name=f\"{stage}_etl\", login=True, password=\"fake\", in_role=[etl_writer, reader])\nRole(name=f\"{stage}_ml\", login=True, password=\"fake\", in_role=[ml_writer, reader])\n# create log role and grant privileges if not test stage\nif stage != \"test\":\nlog_role = Role(name=f\"{stage}_logger\")\nRole(name=f\"{stage}_api\", login=True, password=\"fake\", in_role=[log_role, reader])\ndef main() -&gt; None:  # (2)!\nstages = [\"test\", \"dev\", \"prod\"]\nfor stage in stages:\ndeclare_stage(stage)\nif __name__ == \"__main__\":\nmain()\n</code></pre> <ol> <li>We're keeping the function header and <code>Database</code> definition from before.</li> <li>We're keeping the <code>main</code> function the same as well.</li> </ol> <p>This keeps what was already declared and now declares all the roles. Great! Our example needs a non-default schema next. Let's add a schema.</p>"},{"location":"guide/schemas/","title":"Schemas","text":"<p>First, we'll go over basics and examine the <code>Schema</code> class. Then, we'll continue to build our example. You can also skip ahead to the example.</p>"},{"location":"guide/schemas/#the-schema-class","title":"The Schema class","text":"<p>You can import <code>Schema</code> like so:</p> <pre><code>from dbdeclare.entities import Schema\n</code></pre> <p><code>Schema</code> is a representation of a Postgres schema. It is a database-wide entity. This means each schema in your database (not cluster) must have a unique name. The <code>__init__</code> args correspond to the SQL <code>CREATE SCHEMA</code> arguments found in the Postgres documentation.</p> <p>Take a look at the class docstrings for more detail, like an explanation of the <code>__init__</code> args, the various methods declared, what classes it inherits from, and more.</p>"},{"location":"guide/schemas/#example","title":"Example","text":"<p>Let's keep building our example. In addition to the databases and roles we've declared, we need a <code>log</code> schema for two tables that don't go in the default schema. We need this for each database. Since each database corresponds to each stage, we can simply create a new schema as part of our <code>declare_stage</code> function:</p> <pre><code>from dbdeclare.entities import Database, Role, Schema\ndef declare_stage(stage: str) -&gt; None:\ndb = Database(name=stage)\n# \"groups\" aka non-login roles\netl_writer = Role(name=f\"{stage}_etl_writer\")\nml_writer = Role(name=f\"{stage}_ml_writer\")\nreader = Role(name=f\"{stage}_reader\")\n# \"users\" aka login roles\nRole(name=f\"{stage}_etl\", login=True, password=\"fake\", in_role=[etl_writer, reader])\nRole(name=f\"{stage}_ml\", login=True, password=\"fake\", in_role=[ml_writer, reader])\n# create extra schemas\nSchema(name=\"log\", database=db)\n# omitted code below\n</code></pre> <p>Note that we assign the output of our call to <code>Database</code> to a variable now (<code>db</code>) so that we can explicitly refer to it when we create our log <code>Schema</code>. We don't need to create the default schema, as that will already exist when a new database is created.</p> <p>Entire file now:</p> <pre><code>from dbdeclare.entities import Database, Role, Schema\ndef declare_stage(stage: str) -&gt; None:\ndb = Database(name=stage)\n# \"groups\" aka non-login roles\netl_writer = Role(name=f\"{stage}_etl_writer\")\nml_writer = Role(name=f\"{stage}_ml_writer\")\nreader = Role(name=f\"{stage}_reader\")\n# \"users\" aka login roles\nRole(name=f\"{stage}_etl\", login=True, password=\"fake\", in_role=[etl_writer, reader])\nRole(name=f\"{stage}_ml\", login=True, password=\"fake\", in_role=[ml_writer, reader])\n# create extra schemas\nSchema(name=\"log\", database=db)\n# create log role and grant privileges if not test stage\nif stage != \"test\":\nlog_role = Role(name=f\"{stage}_logger\")\nRole(name=f\"{stage}_api\", login=True, password=\"fake\", in_role=[log_role, reader])\ndef main() -&gt; None:\nstages = [\"test\", \"dev\", \"prod\"]\nfor stage in stages:\ndeclare_stage(stage)\nif __name__ == \"__main__\":\nmain()\n</code></pre> <p>This code now declares the databases, roles, and schemas we need. All that's left is to declare the tables + columns, grant privileges, then actually push all this to the cluster. Let's add some tables.</p>"},{"location":"guide/tables/","title":"Tables (and columns)","text":"<p>Tables and columns are declared via SQLAlchemy, a proven, robust tool that this package is built on. You can optionally declare tables and columns via SQLModel, a project that combines a lot of the benefits of SQLA with Pydantic, resulting in highly reusable models for both data definition and strong typing throughout your application. In either case, you declare tables and columns through another library, then simply refer to them from DbDeclare via the <code>DatabaseContent</code> class.</p> <p>We'll go over the basics and examine the <code>DatabaseContent</code> class, then we'll continue to build our example. You can also skip ahead to the example.</p>"},{"location":"guide/tables/#the-databasecontent-class","title":"The DatabaseContent class","text":"<p>You can import <code>DatabaseContent</code> like so:</p> <pre><code>from dbdeclare.entities import DatabaseContent\n</code></pre> <p><code>DatabaseContent</code> is a wrapper around a SQLAlchemy base. It is a database-wide entity, which means it must be uniquely named within a database. The <code>__init__</code> args are a combination of inherited utility and some necessary references: you must refer to which <code>Database</code> this content belongs to, and which schemas (if non-default) it depends on.</p> <p>Take a look at the class docstrings for more detail, like an explanation of the <code>__init__</code> args, the various methods defined, what classes it inherits from, and more. <code>DatabaseContent</code> is slightly odd because it does not have 1-to-1 correspondence with a Postgres entity, and many of the internal methods call SQLA table methods in turn. The source code is well worth looking at for this one.</p>"},{"location":"guide/tables/#example","title":"Example","text":"<p>Let's keep building our example. We have our databases, roles, and extra schemas. Let's declare our tables and columns via SQLA then refer to them via the <code>DatabaseContent</code> class:</p> <pre><code>from sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column\nfrom dbdeclare.entities import Database, DatabaseContent, Role, Schema\nclass ExampleBase(DeclarativeBase):\npass\nclass Article(ExampleBase):\n__tablename__ = \"article\"\nid: Mapped[int] = mapped_column(primary_key=True)\nclass Keyword(ExampleBase):\n__tablename__ = \"keyword\"\nid: Mapped[int] = mapped_column(primary_key=True)\nclass Cluster(ExampleBase):\n__tablename__ = \"cluster\"\nid: Mapped[int] = mapped_column(primary_key=True)\nclass BadRequest(ExampleBase):\n__tablename__ = \"bad_request\"\n__table_args__ = {\"schema\": \"log\"}\nid: Mapped[int] = mapped_column(primary_key=True)\nclass GoodRequest(ExampleBase):\n__tablename__ = \"good_request\"\n__table_args__ = {\"schema\": \"log\"}\n# omitted code below\n</code></pre> <p>In the code above, we import <code>DatabaseContent</code> from <code>dbdeclare</code> and we import <code>DeclarativeBase</code> from <code>sqlalchemy</code>. We then define a base and a bunch of tables. Please refer to SQLA documentation for more information on how to declare tables and columns. Now let's refer to the base:</p> <pre><code># omitted code above\ndef declare_stage(stage: str) -&gt; None:\n# omitted code between\n# create extra schemas\nlog_schema = Schema(name=\"log\", database=db)\n# create db content\n# omitted code below\n</code></pre> <p>We update the schema definition so that we store a reference to it in <code>log_schema</code>. We then declare our <code>DatabaseContent</code> and have it point to <code>db</code>, <code>ExampleBase</code>, and <code>log_schema</code> so that Postgres will know exactly where to put these tables and what entities need to exist before these tables can exist.</p> <p>This code now declares the databases, roles, schemas, tables, and columns we need. Apart from actually creating all this in the cluster, all we need to do is grant privileges.</p>"}]}